from backbone.PVTv2.pvtv2_encoder import pvt_v2_b0
import torch
import torch.nn.functional as F
from torch import nn
import pywt
import numpy as np
from Model.model.MINE.norm import BasicConv2d
from torch_geometric.nn import ChebConv


class GraphWaveletTransform(nn.Module):
    def __init__(self, in_channels, out_channels, K=3):
        super(GraphWaveletTransform, self).__init__()
        self.cheb_conv = ChebConv(in_channels, out_channels, K)

    def forward(self, x, edge_index):
        out = self.cheb_conv(x, edge_index)
        return out


class DAHM(nn.Module):
    def __init__(self, out_x):
        super(DAHM, self).__init__()
        in_x = out_x * 2
        self.con = nn.Conv2d(in_x, out_x, 1)
        self.up = nn.Upsample(scale_factor=0.5, mode="bilinear")
        self.b_1 = nn.Conv2d(in_x, out_x, kernel_size=1)
        self.wavelet = 'db2'
        self.phase_conv = nn.Conv2d(3, out_x, kernel_size=1) 
        self.graph_wavelet = GraphWaveletTransform(out_x, out_x)
        self.feature_weights = nn.Sequential(
            nn.Conv2d(out_x, out_x, kernel_size=1),
            nn.Sigmoid()
        )

    def wavelet_phase(self, x1, x2):
        B, C, H, W = x1.shape
        x1_np = x1.detach().cpu().numpy()
        x2_np = x2.detach().cpu().numpy()

        phases = []
        for c in range(C):
            coeffs1 = pywt.dwt2(x1_np[:, c], self.wavelet)
            coeffs2 = pywt.dwt2(x2_np[:, c], self.wavelet)

            _, (LH1, HL1, HH1) = coeffs1
            _, (LH2, HL2, HH2) = coeffs2

            phase_LH = np.angle(LH1 + LH2) / 2
            phase_HL = np.angle(HL1 + HL2) / 2
            phase_HH = np.angle(HH1 + HH2) / 2

            # 堆叠相位
            phases.append(np.stack([phase_LH, phase_HL, phase_HH], axis=1))

        phases = np.stack(phases, axis=2)
        phases = torch.from_numpy(phases).float().to(x1.device)

        return phases

    def image_to_graph(self, x):
        B, C, H, W = x.shape
        x_flat = x.view(B, C, -1).permute(0, 2, 1)

        row = torch.arange(H * W).view(1, -1).repeat(B, 1)
        col = torch.arange(H * W).view(1, -1).repeat(B, 1)
        edge_index = torch.stack([
            torch.cat([row, col], dim=1),
            torch.cat([col, row], dim=1)
        ], dim=0).to(x.device)

        return x_flat, edge_index

    def graph_to_image(self, x, B, C, H, W):
        return x.permute(0, 2, 1).view(B, C, H, W)

    def forward(self, r, d):
        r_weight = self.feature_weights(r)
        d_weight = self.feature_weights(d)
        B, C, H, W = r.shape
        r_graph, edge_index = self.image_to_graph(r)
        d_graph, _ = self.image_to_graph(d)
        r_wavelet = self.graph_wavelet(r_graph, edge_index)
        d_wavelet = self.graph_wavelet(d_graph, edge_index)
        r_wavelet = self.graph_to_image(r_wavelet, B, C, H, W)
        d_wavelet = self.graph_to_image(d_wavelet, B, C, H, W)

        combined_phase = self.wavelet_phase(r_wavelet, d_wavelet).mean(2)

        phase = self.phase_conv(combined_phase)
        phase = F.interpolate(phase, size=r.shape[2:], mode='bilinear', align_corners=False)

        RD = r_wavelet * torch.cos(phase) + 1j * d_wavelet * torch.sin(phase)
        RD = torch.cat([r_weight * RD.real, d_weight * RD.imag], dim=1)

        return self.b_1(RD)


class FM(nn.Module):
    def __init__(self, inc):
        super(FM, self).__init__()
        self.up = nn.Upsample(scale_factor=0.5, mode='bilinear', align_corners=False)
        self.con2 = nn.Conv2d(inc, inc // 2, 1)
        self.con3 = BasicConv2d(inc, inc, 1)
        self.fun = DAHM(inc // 2)

    def forward(self, x, y, s):
        x = self.con2(x)
        y = self.con2(y)
        s = self.up(s)
        s = self.fun(y, s)
        combined = torch.cat([x, s], dim=1)
        s = self.con3(combined)
        return s


class END(nn.Module):
    def __init__(self, in_channel):
        super(END, self).__init__()
        self.conv0 = BasicConv2d(in_channel * 2, in_channel, 3, 1, 1)
        self.up = nn.Upsample(scale_factor=2, mode='bilinear', align_corners=False)

    def forward(self, x1, x2):
        x2 = self.up(x2)
        out = torch.cat((x1 + x2, x1 * x2), dim=1)
        out = self.conv0(out)
        return out

class decode_f(nn.Module):
    def __init__(self, in_channel, out_channel,version=1):
        super(decode_f, self).__init__()
        self.conv2 = nn.Conv2d(in_channel, out_channel, kernel_size=3, stride=1, padding=1)
        self.conv1 = nn.Conv2d(out_channel, out_channel, kernel_size=3, stride=1, padding=1)
        self.conv3 = BasicConv2d(out_channel * 2, out_channel, kernel_size=3, stride=1, padding=1)
        self.up = nn.Upsample(scale_factor=2, mode='bilinear', align_corners=False)
        self.version = version
        self.exp_decode = nn.Sequential(
            nn.Conv2d(out_channel, out_channel, kernel_size=3, padding=1),
            nn.BatchNorm2d(out_channel),
            nn.GELU(),  # Using GELU for better gradient flow
            nn.Conv2d(out_channel, out_channel, kernel_size=3, padding=1),
            nn.BatchNorm2d(out_channel)
        )
    def forward(self, decode_f1, decode_f2):
        # 特征提取和上采样
        if self.version == 1:
            decode_f1 = self.conv1(decode_f1)
            decode_f2 = self.up(self.conv2(decode_f2))
        else:
            decode_f1 = self.conv2(decode_f1)
            decode_f2 = self.up(self.conv1(decode_f2))
        global_fusion1 = torch.mul(decode_f1, decode_f2)

        out = self.conv3(torch.cat((decode_f1, global_fusion1), dim=1))
        return out


class MCLPvt_Net2(nn.Module):
    global backbone_rgb

    def __init__(self,inc=128):
        super(MCLPvt_Net2, self).__init__()

        self.stage_r = pvt_v2_b0(pretrained=True)
        self.stage_d = pvt_v2_b0(pretrained=True)

        self.layer1_r = self.stage_r.stage1
        self.layer2_r = self.stage_r.stage2
        self.layer3_r = self.stage_r.stage3
        self.layer4_r = self.stage_r.stage4

        self.layer1_d = self.stage_d.stage1
        self.layer2_d = self.stage_d.stage2
        self.layer3_d = self.stage_d.stage3
        self.layer4_d = self.stage_d.stage4
        self.fuse1 = DAHM(32)
        self.fuse2 = FM(64)
        self.fuse3 = FM(128)
        self.fuse4 = FM(256)
        self.fusion = END(128)

        self.decode_f3 = decode_f(256, 128, version=1)
        self.decode_f2 = decode_f(64, 128, version=2)
        self.decode_f1 = decode_f(32, 128, version=2)

        self.side_fusion2 = nn.Conv2d(128, 3, kernel_size=3, stride=1, padding=1)
        self.side_fusion3 = nn.Conv2d(128, 3, kernel_size=3, stride=1, padding=1)
        self.linear_out = nn.Sequential(nn.Conv2d(inc, inc // 2, 3, 1, 1, bias=False),
                                        nn.BatchNorm2d(inc // 2),
                                        nn.ReLU(True),
                                        nn.Conv2d(inc // 2, 3, 3, 1, 1, bias=False))

        self.con1 = nn.Conv2d(160, 128, 1)
        self.up = nn.Upsample(scale_factor=2, mode='bilinear')

    def forward(self, rgb, depth):
        raw_size = rgb.size()[2:]

        r1 = self.layer1_r(rgb)
        r2 = self.layer2_r(r1)
        r3 = self.layer3_r(r2)
        r4 = self.layer4_r(r3)

        d1 = self.layer1_d(depth)
        d2 = self.layer2_d(d1)
        d3 = self.layer3_d(d2)
        d4 = self.layer4_d(d3)

        r3 = self.con1(r3)
        d3 = self.con1(d3)

        fuse1 = r1
        fuse2 = self.fuse2(r2, d2, fuse1)
        fuse3 = self.fuse3(r3, d3, fuse2)
        fuse4 = self.fuse4(r4, d4, fuse3)

        out3 = self.decode_f3(fuse3, fuse4)
        out2 = self.decode_f2(fuse2, out3)
        out1 = self.decode_f1(fuse1, out2)

        T3 = F.interpolate(self.side_fusion3(out3), size=raw_size, mode='bilinear')
        #T2 = self.fusion(out2, out3)
        T2 = F.interpolate(self.side_fusion2(out2), size=raw_size, mode='bilinear')
        T1 = self.fusion(out1, out2)
        T1 = F.interpolate(self.linear_out(T1), size=raw_size, mode='bilinear')
        return T1, T2, T3,out3,out2,out1

    def forward(self, input):
        rgb = input[:, :3]
        modal_x = input[:, 3:]
        modal_x = torch.cat((modal_x, modal_x, modal_x), dim=1)

        T1, T2, T3,out3,out2,out1 = self.encode_decode(rgb, modal_x)

        return T1, T2, T3#,out3,out2,out1

